---
title: "SYÖ! Helsinki 2019 restaurant reviews - Web Scraping and Browser Automation"
date: 2019-02-08
tags: [robotframework, webscraping]
header:
  image: "/assets/images/syoHel2019/syoHel2019.jpg"
excerpt: "Robot Framework, Web Scraping"
---

This project uses web scraping together with browser automation to automatically get review scores for Helsinki located restaurants participating in SYÖ! campaign of 10€ dishes. In first part all the name's of restaurants were gathered using BeautifulSoup web scraping for Python. After this the text is manipulated to Google Maps and TripAdvisor search links which are used as input for our Robot Framework script that gathers the review scores. After this the results are examined and saved using this Jupyer Notebook. The motivation behind this project was automating decision-making... and to learn what the tools used can potentially do.

To check how the website looked like you can visit its archive at: https://web.archive.org/web/20190126133843/https://www.city.fi/syo/helsinki

<h2>Web Scraping using BeautifulSoup</h2>

Lets begin by importing needed libraries:


```python
from bs4 import BeautifulSoup
import pandas as pd
import requests
```

Next we will need the campaign's page url, using which we can build the soup from html:

(to replicate the results please use https://web.archive.org/web/20190126133843id_/https://www.city.fi/syo/helsinki as url)


```python
url = 'https://www.city.fi/syo/helsinki'
r = requests.get(url)
```


```python
soup = BeautifulSoup(r.text)
```

After inspecting the structure of obtained soup, it's easy to notice that the names are contained within h3 tags each, and more specifically rows 2-98. We extract these out and format them as text


```python
r1 = soup.find_all('h3')[1:98]
r1[0:5]
```




    [<h3><a data-ad-id="1137" href="https://www.city.fi/syo/helsinki/1137">Nepalilainen Ravintola Manakamana</a></h3>,
     <h3><a data-ad-id="1191" href="https://www.city.fi/syo/helsinki/1191">Sports Academy Helsinki</a></h3>,
     <h3><a data-ad-id="759" href="https://www.city.fi/syo/helsinki/759">Woolshed – Australian Gastropub</a></h3>,
     <h3><a data-ad-id="1177" href="https://www.city.fi/syo/helsinki/1177">Ravintola China Flavor</a></h3>,
     <h3><a data-ad-id="1188" href="https://www.city.fi/syo/helsinki/1188">Vapiano Itis</a></h3>]




```python
r2 = [x.getText() for x in r1]
```

Next the restaurant names are transformed into GMaps and TripAdvisor links:


```python
r3 = [str('https://www.google.com/maps/search/' + x).replace(' ', '+') for x in r2]
```


```python
TA1 = 'https://www.tripadvisor.fi/Search?geo=8659079&searchNearby=&pid=3825&redirect=&startTime=1548662491065&uiOrigin=MASTHEAD&q='
TA2 = '&supportedSearchTypes=find_near_stand_alone_query&enableNearPage=true&returnTo=https%253A__2F____2F__www__2E__tripadvisor__2E__fi__2F__Restaurants__2D__g8659079__2D__Uusimaa__2E__html&searchSessionId=B23DB8289BCAC86AC32C2E4551BE625B1548662487453ssid&social_typeahead_2018_feature=true&sid=B23DB8289BCAC86AC32C2E4551BE625B1548662494607&rf=1'

r4 = [str(TA1 + str(x).replace(' ', '+') + TA2) for x in r2]
```

Here is an example of one TripAdvisor search link generated:


```python
r4[44]
```




    'https://www.tripadvisor.fi/Search?geo=8659079&searchNearby=&pid=3825&redirect=&startTime=1548662491065&uiOrigin=MASTHEAD&q=Nepalilainen+Ravintola+Tilicho&supportedSearchTypes=find_near_stand_alone_query&enableNearPage=true&returnTo=https%253A__2F____2F__www__2E__tripadvisor__2E__fi__2F__Restaurants__2D__g8659079__2D__Uusimaa__2E__html&searchSessionId=B23DB8289BCAC86AC32C2E4551BE625B1548662487453ssid&social_typeahead_2018_feature=true&sid=B23DB8289BCAC86AC32C2E4551BE625B1548662494607&rf=1'



To save and further use the data pandas DataFrame is created:


```python
df = pd.DataFrame(columns=['Name', 'GMaps', 'TA'])
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>GMaps</th>
      <th>TA</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




```python
df['Name'] = r2
df['GMaps'] = r3
df['TA'] = r4
df_sorted = df.sort_values(by='Name').reset_index(drop=True)
```

The scraped data is saved to .csv file for Robot Framework script to read and run on:


```python
df_sorted.to_csv("syoHel2019.csv",header=False)
```

<h2>Robot Framework browser automation</h2>

"Robot Framework is a generic test automation framework for acceptance testing and acceptance test-driven development (ATDD). It has easy-to-use tabular test data syntax and it utilizes the keyword-driven testing approach. Its testing capabilities can be extended by test libraries implemented either with Python or Java, and users can create new higher-level keywords from existing ones using the same syntax that is used for creating test cases."

Read more at their homepage https://robotframework.org/

In this project the Robot Framework is used with SeleniumLibrary that is designed for browser automation. Below you can find a short example of the code, link to full robot and a video of it's operation.


```python
*** Settings ***
Documentation                                       This is the main script for running the automation
Resource                                            ../Resources/Common.robot
Resource                                            ../Resources/GMaps.robot
Resource                                            ../Resources/TA.robot
Resource                                            ../Resources/DataManager.robot

Test Setup                                          Begin Web Test
Test Teardown                                       End Web Test

# run command:
# robot -d results tests/main.robot

*** Variables ***
${BROWSER} =                                        chrome
${CSV_PATH} =                                       C:\\robotFW\\syoHel2019_final\\Data\\syoHel2019.csv
${RESULT_PATH_GMAPS} =                              C:\\robotFW\\syoHel2019_final\\Data\\GMaps.csv
${RESULT_PATH_TA} =                                 C:\\robotFW\\syoHel2019_final\\Data\\TA.csv
@{GMapsResultsList} =  
@{TAResultsList} =  

*** Test Cases ***
Extract CSV Data
    ${DataCSV} =  DataManager.Get CSV Data          ${CSV_PATH}
    GMaps.Get all the Review Scores                 ${DataCSV}
    Log  ${GMapsResultsList}
    TA.Get all the Review Scores                    ${DataCSV}
    Log  ${TAResultsList}
    DataManager.Write Results                       ${RESULT_PATH_GMAPS}    ${GMapsResultsList}     GMapsScore
    DataManager.Write Results                       ${RESULT_PATH_TA}       ${TAResultsList}        TAScore
```

Because of different writing style in the SYÖ! campaign page than in Google Maps and TripAdvisor the robot doesn't always find correct (or at all) score, but most of the time it does its job. In TripAdvisor the robot knows if it opened something else than restaurant review by accident (like shopping centre or hotel) and ignores these results.


<iframe width="560" height="315" src="https://www.youtube.com/embed/DgV7siyXkrk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<h2>Coninuing after Robot Framework part:</h2>

Now that the review scores have been saved to another .csv file, we can take a look at them by reading them into pandas DataFrame:


```python
TA = pd.read_csv('TA.csv')
GMaps = pd.read_csv('GMaps.csv')
TA.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TAScore</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4.5</td>
    </tr>
  </tbody>
</table>
</div>



We know that the robot went through the list of restaurants in same order as in the scraped list, so we can combine restaurant names with the reviews:


```python
df_sorted['GMapsScore'] = GMaps
df_sorted['TAScore'] = TA
```

Now that the scores have been attained, the GMaps and TA links are no longer needed:


```python
df_sorted.drop(columns=['GMaps','TA'], inplace=True)
```

Let's check out whar were the most common Google Maps and TA scores, and how many NA's there are in each:


```python
df_sorted['GMapsScore'].value_counts()
```




    4.1    17
    4.3    14
    3.8    10
    4.0    10
    4.2     9
    4.4     6
    3.9     5
    3.7     4
    4.8     3
    4.6     2
    3.4     2
    2.7     1
    3.2     1
    3.0     1
    3.5     1
    4.9     1
    4.5     1
    Name: GMapsScore, dtype: int64




```python
df_sorted[df_sorted['GMapsScore'].isna()]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>GMapsScore</th>
      <th>TAScore</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>25</th>
      <td>Just Vege</td>
      <td>NaN</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Momotoko</td>
      <td>NaN</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Nepalilainen Ravintola Base Camp Hakaniemi</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Nepalilainen Ravintola Tilicho</td>
      <td>NaN</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>60</th>
      <td>Ravintola Aangan</td>
      <td>NaN</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>81</th>
      <td>Tamarin Jumbo</td>
      <td>NaN</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>83</th>
      <td>Thai Orchid Dixi</td>
      <td>NaN</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>92</th>
      <td>Vibami – Vietnamese Kitchen Eerikinkatu</td>
      <td>NaN</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Zilla</td>
      <td>NaN</td>
      <td>3.5</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_sorted['TAScore'].value_counts()
```




    4.0    34
    3.5    19
    4.5    16
    3.0     4
    2.5     2
    0.0     1
    5.0     1
    Name: TAScore, dtype: int64




```python
df_sorted[df_sorted['TAScore'].isna()]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>GMapsScore</th>
      <th>TAScore</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>Bites Burgers Kamppi</td>
      <td>4.9</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Grand Georgia</td>
      <td>3.5</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Haiku Kämp Galleria</td>
      <td>4.1</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Hard Rock Cafe Helsinki</td>
      <td>4.3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Haru Plus</td>
      <td>4.4</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Hokkaidosushi</td>
      <td>4.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Itamae Forum</td>
      <td>3.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Levant REDI</td>
      <td>4.3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Momotoko Iso Omena</td>
      <td>4.3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Momotoko Jumbo</td>
      <td>4.3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Nepalilainen Ravintola Base Camp Hakaniemi</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>51</th>
      <td>Nepalilainen ravintola Mount Everest Kamppi</td>
      <td>4.1</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>52</th>
      <td>Nepalilainen ravintola Satkar Kamppi</td>
      <td>4.2</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>56</th>
      <td>Pancho Villa Itis</td>
      <td>3.4</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>57</th>
      <td>Pancho Villa Kluuvi</td>
      <td>3.7</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>66</th>
      <td>Ravintola Penny Helsinki</td>
      <td>4.3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>77</th>
      <td>Sports Academy Helsinki</td>
      <td>3.8</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>80</th>
      <td>Tamarin Iso Omena</td>
      <td>4.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Tamarin Tikkurila</td>
      <td>4.2</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>84</th>
      <td>Thai Orchid Kamppi</td>
      <td>3.9</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



Now we can filter out the most potential group of restaurants to go to:


```python

```

Lastly, saving the reviews with restaurant names to .xlsx file for later use:


```python
df_sorted.to_excel('syoHel2019_results.xlsx')
```
